---
permalink: /
title: "About"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hello! I am **Zonglin Yang**, a first-year Ph.D. student in Nanyang Technological Univeristy, where he is supervised by [Erik Cambria](https://sentic.net/about/). I obtained my undergraduate’s degree at Huazhong Univeristy of Science and Technology, supervised by [Xinggang Wang](https://xinggangw.info/). I obtained my master's degree at Cornell University, supervised by [Claire Cardie](https://www.cs.cornell.edu/home/cardie/) and [Xinya Du](https://xinyadu.github.io/).
Previously, I interned at Microsoft Research Asia with [Li Dong](http://dong.li/).


Research
======
My current research centered around knowledge & reasoning in Natural Language Processing.

Some of my past representative research are:

(1) Analyze and augment existing pretrained (large) language model's ability on specified and fundamental types of reasoning, e.g., [Inductive Reasoning](https://arxiv.org/pdf/2212.10923.pdf).

(2) Bridging research from classic AI (Knowledge Representation and Reasoning) to Natural Language Processing, e.g., [Case-based Reasoning](http://sentic.net/commonsense-knowledge-base-completion.pdf).


<!-- My primary research goal is to apply Deep Learning for Natural Language Processing and develop **Language Technology for All**. To achievethis goal and make language technology accessible in most people’s lives, I identify two major research topics that I’m interested in: **efficiency** and **trustworthiness** of NLP models. Efficiency involves both the amount of **computation** and **data** required for (pre-)training and using NLP models. Trustworthiness involves the **interpretability**, **fairness**, and **robustness** with respect to adversarial attacks and out-of-distribution samples.  

Specifically I am interested in the following research topics:  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Natural language generation, creative text generation, evaluation for NLG models.**  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Commonsense reasoning and knowledge-based reasoning.**  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Robust NLP models for OOD samples and reducing spurious dataset biases.**  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Interpretability, explainability, biases, and fairness for NLP models.**  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Green NLP, Low resource NLP, and Learning NLP models from high-level supervision**  
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Multi-modality**   -->
<!-- I am open to academic collaborations and please drop me an email if you are interested in collaborating with me.   -->

News
======
\[2023.01]. Got one paper accepted to **EACL 2023**. Thanks to all my collaborators!  

\[2020.10]. Got one paper accepted to **EMNLP 2020 (findings)**. Thanks to all my collaborators!  


Academic Services
======

##### Conference Reviewer: 
* ACL 2023

##### Journal Reviewer: 
* IEEE Transactions on Affective Computing
* Knowledge-Based Systems
* Information Fusion
* Artificial Intelligence Review
* Cognitive Computation


<!-- \[2018.12\] Start my research internship at at [NLC Group @ Microsoft Research Asia](https://www.microsoft.com/en-us/research/group/natural-language-computing/), advised by Dr. Tao Ge.  

\[2018.8\] Start my Master study at NLSDE Lab in Beihang University, advised by Prof. Ke Xu   -->

<!-- Personal information
------
I am a big fan of Harry Potter, Real Madrid, and Cristiano Ronaldo. I enjoy reading books (especially sci-fictions) and playing games (including FIFA, League of Legends, etc.) in my free time. -->
